{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: resnet50 as the base model\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "import sys\n",
    "sys.path.append('/opt/code/face/dual_shot')\n",
    "import numpy as np\n",
    "from net.dual_shot import test_net\n",
    "from prepare_data.generator import image_reader,augment\n",
    "from prepare_data.augment import Augmentation\n",
    "from prepare_data.widerface import WIDERFaceDetection\n",
    "from dual_conf import current_config as conf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth= True\n",
    "sess = tf.Session(config=config)\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1,  1,  1,  1,  0, -1, -1],\n",
       "       [-1,  1, -1,  1,  0, -1,  1,  0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_target = np.random.randint(-1,2,[2,8])\n",
    "cls_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8,  6],\n",
       "        [ 1,  9],\n",
       "        [ 2,  3],\n",
       "        [ 4,  8],\n",
       "        [ 3,  5],\n",
       "        [ 7,  1],\n",
       "        [ 6,  7],\n",
       "        [ 4, -1]],\n",
       "\n",
       "       [[ 5,  0],\n",
       "        [-1,  7],\n",
       "        [ 8,  3],\n",
       "        [ 3,  7],\n",
       "        [ 0,  8],\n",
       "        [ 1,  7],\n",
       "        [-1,  8],\n",
       "        [ 3,  3]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_logits = np.random.randint(-1,10,[2,8,2])\n",
    "predict_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_target = tf.constant(cls_target)\n",
    "predict_logits = tf.constant(predict_logits,tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = tf.where(tf.not_equal(cls_target, 0))\n",
    "cls_target = tf.gather_nd(cls_target, train_indices)\n",
    "cls_target = tf.where(cls_target > 0, cls_target, tf.zeros_like(cls_target))\n",
    "cls_target = tf.one_hot(cls_target, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove un-trained anchors from pred logit\n",
    "logit0 = tf.gather_nd(predict_logits[..., 0], train_indices)\n",
    "logit1 = tf.gather_nd(predict_logits[..., 1], train_indices)\n",
    "predict_logits = tf.stack([logit0, logit1], axis=1)\n",
    "predict_logits = tf.cast(predict_logits, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Where_33:0\", shape=(?, 2), dtype=int64) \n",
      " [[0 0]\n",
      " [0 1]\n",
      " [0 3]\n",
      " [0 5]\n",
      " [0 7]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 3]\n",
      " [1 5]]\n",
      "Tensor(\"one_hot_13:0\", shape=(?, 2), dtype=float32) \n",
      " [[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Tensor(\"stack_13:0\", shape=(?, 2), dtype=float64) \n",
      " [[-1.  4.]\n",
      " [ 1.  6.]\n",
      " [ 1.  7.]\n",
      " [ 6.  9.]\n",
      " [ 4.  5.]\n",
      " [ 1.  5.]\n",
      " [ 4.  8.]\n",
      " [ 5.  4.]\n",
      " [ 1.  9.]]\n"
     ]
    }
   ],
   "source": [
    "to_run = [train_indices,cls_target,predict_logits]\n",
    "for i in to_run:\n",
    "    print(i,'\\n',sess.run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_to_rank = log_sum_exp(cls_target,predict_logits)\n",
    "# to_run = [loss_to_rank]\n",
    "# for i in to_run:\n",
    "#     print(i,'\\n',sess.run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stack:0\", shape=(?, 2), dtype=float64) \n",
      " [[ 2.  5.]\n",
      " [-1.  1.]\n",
      " [ 8.  3.]\n",
      " [-1.  6.]\n",
      " [ 2.  0.]\n",
      " [ 4.  2.]\n",
      " [ 3.  4.]]\n",
      "Tensor(\"one_hot:0\", shape=(?, 2), dtype=float32) \n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "Tensor(\"GatherNd_3:0\", shape=(?,), dtype=float64) \n",
      " [ 2.  1.  8. -1.  0.  2.  4.]\n",
      "Tensor(\"sub_1:0\", dtype=float64) \n",
      " [3.04858735e+00 1.26928011e-01 6.71534849e-03 7.00091147e+00\n",
      " 2.12692801e+00 2.12692801e+00 3.13261688e-01]\n"
     ]
    }
   ],
   "source": [
    "cls_target,pred_logit = cls_target,predict_logits\n",
    "logit_max = tf.reduce_max(pred_logit)\n",
    "loss = tf.log(tf.reduce_sum(tf.exp(pred_logit - logit_max), 1, keepdims=True)) + logit_max\n",
    "cls_indice = tf.where(cls_target>=1) \n",
    "anchor_cls_logit = tf.gather_nd(pred_logit,cls_indice)\n",
    "loss = tf.squeeze(loss)\n",
    "loss = loss - anchor_cls_logit\n",
    "\n",
    "\n",
    "to_run = [pred_logit,cls_target,anchor_cls_logit,loss]\n",
    "for i in to_run:\n",
    "    print(i,'\\n',sess.run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", dtype=int64) \n",
      " [1 4 5 6 3 0]\n",
      "Tensor(\"one_hot:0\", shape=(?, 2), dtype=float32) \n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "Tensor(\"stack:0\", shape=(?, 2), dtype=float64) \n",
      " [[ 2.  5.]\n",
      " [-1.  1.]\n",
      " [ 8.  3.]\n",
      " [-1.  6.]\n",
      " [ 2.  0.]\n",
      " [ 4.  2.]\n",
      " [ 3.  4.]]\n",
      "Tensor(\"GatherV2:0\", dtype=float32) \n",
      " [[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Tensor(\"GatherV2_1:0\", dtype=float64) \n",
      " [[-1.  1.]\n",
      " [ 2.  0.]\n",
      " [ 4.  2.]\n",
      " [ 3.  4.]\n",
      " [-1.  6.]\n",
      " [ 2.  5.]]\n"
     ]
    }
   ],
   "source": [
    "loss = tf.cast(cls_target[:,0],tf.float64)*loss # set loss for pos anchor to 0\n",
    "_, neg_ind  = tf.nn.top_k(loss, 2)\n",
    "pos_ind = tf.squeeze(tf.where(cls_target[:,1]>=1))\n",
    "pos_ind = tf.cast(pos_ind,tf.int64)\n",
    "neg_ind = tf.cast(neg_ind,tf.int64)\n",
    "all_ind = tf.concat([pos_ind,neg_ind],axis=0)\n",
    "# cls_target = tf.gather(cls_target,all_ind)\n",
    "# pred_logit = tf.gather(pred_logit,all_ind)\n",
    "to_run = [all_ind,cls_target,pred_logit,tf.gather(cls_target,all_ind),tf.gather(pred_logit,all_ind)]\n",
    "for i in to_run:\n",
    "    print(i,'\\n',sess.run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Squeeze:0\", dtype=float64) Tensor(\"GatherNd_3:0\", shape=(?,), dtype=float64)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [11] vs. [7]\n\t [[Node: sub_1 = Sub[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Squeeze, GatherNd_3)]]\n\nCaused by op 'sub_1', defined at:\n  File \"/root/anaconda3/envs/keras/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-317c329a47d6>\", line 119, in <module>\n    see = cls_loss(cls_target, predict_logits)\n  File \"<ipython-input-3-317c329a47d6>\", line 71, in cls_loss\n    cls_target, predict_logits = hard_neg_mining(cls_target, predict_logits)\n  File \"<ipython-input-3-317c329a47d6>\", line 37, in hard_neg_mining\n    loss_to_rank = log_sum_exp(cls_target, predict_logits)\n  File \"<ipython-input-3-317c329a47d6>\", line 26, in log_sum_exp\n    loss = loss - anchor_cls_logit\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8009, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [11] vs. [7]\n\t [[Node: sub_1 = Sub[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Squeeze, GatherNd_3)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [11] vs. [7]\n\t [[Node: sub_1 = Sub[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Squeeze, GatherNd_3)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-317c329a47d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [11] vs. [7]\n\t [[Node: sub_1 = Sub[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Squeeze, GatherNd_3)]]\n\nCaused by op 'sub_1', defined at:\n  File \"/root/anaconda3/envs/keras/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-317c329a47d6>\", line 119, in <module>\n    see = cls_loss(cls_target, predict_logits)\n  File \"<ipython-input-3-317c329a47d6>\", line 71, in cls_loss\n    cls_target, predict_logits = hard_neg_mining(cls_target, predict_logits)\n  File \"<ipython-input-3-317c329a47d6>\", line 37, in hard_neg_mining\n    loss_to_rank = log_sum_exp(cls_target, predict_logits)\n  File \"<ipython-input-3-317c329a47d6>\", line 26, in log_sum_exp\n    loss = loss - anchor_cls_logit\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 847, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8009, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/root/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [11] vs. [7]\n\t [[Node: sub_1 = Sub[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Squeeze, GatherNd_3)]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 _*-\n",
    "\"\"\"\n",
    "@author: danna.li\n",
    "@date: 2019/4/25\n",
    "@file: loss_func.py\n",
    "@description:\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from dual_conf import current_config as conf\n",
    "\n",
    "\n",
    "def log_sum_exp(cls_target, predict_logits):\n",
    "    \"\"\"un-averaged confidence loss across all examples in a batch.\n",
    "    :param cls_target: 2-d tensor,[num_anchors,2 ]; 1,0 for pos,neg anchors respectively\n",
    "    :param predict_logits: 2-d tensor,[num_anchors,2] 2 for fg and bg\n",
    "    :return: loss,1-D tensor\n",
    "    \"\"\"\n",
    "    logit_max = tf.reduce_max(predict_logits)\n",
    "    loss = tf.log(tf.reduce_sum(tf.exp(predict_logits - logit_max), 1, keepdims=True)) + logit_max\n",
    "    cls_indice = tf.where(cls_target >= 1)\n",
    "    anchor_cls_logit = tf.gather_nd(predict_logits, cls_indice)\n",
    "    loss = tf.squeeze(loss)\n",
    "    print(loss,anchor_cls_logit)\n",
    "    loss = loss - anchor_cls_logit\n",
    "    return loss\n",
    "\n",
    "\n",
    "def hard_neg_mining(cls_target, predict_logits):\n",
    "    \"\"\"\n",
    "    select top 80 negtive anchors the contribute most loss to do the backward pass\n",
    "    :param cls_target:2-d tensor,[num_anchors,2 ]; 1,0 for pos,neg anchors respectively\n",
    "    :param predict_logits: 2-d tensor,[num_anchors,2] 2 for fg and bg\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loss_to_rank = log_sum_exp(cls_target, predict_logits)\n",
    "    loss_to_rank = tf.cast(cls_target[:, 0], tf.float64) * loss_to_rank  # set loss for pos anchor to 0\n",
    "    _, neg_ind = tf.nn.top_k(loss_to_rank, 2)\n",
    "    pos_ind = tf.squeeze(tf.where(cls_target[:, 1] >= 1))\n",
    "    pos_ind = tf.cast(pos_ind, tf.int64)\n",
    "    neg_ind = tf.cast(neg_ind, tf.int64)\n",
    "    all_ind = tf.concat([pos_ind, neg_ind], axis=0)\n",
    "    cls_target = tf.gather(cls_target,all_ind)\n",
    "    predict_logits = tf.gather(predict_logits,all_ind)\n",
    "    return cls_target, predict_logits\n",
    "\n",
    "\n",
    "def cls_loss(cls_target, predict_logits):\n",
    "    \"\"\"\n",
    "    :param cls_target:2-d array,[batch_num,num_anchors]; 1,-1,0 for pos,neg and un-train anchors respectively\n",
    "    :param predict_logits: 3-d array,[batch_num,num_anchors,2] fg or bg\n",
    "    :return: classification loss of training anchors\n",
    "    \"\"\"\n",
    "    # remove un-trained anchors from cls_target and make cls_target to one-hot format\n",
    "    train_indices = tf.where(tf.not_equal(cls_target, 0))\n",
    "    cls_target = tf.gather_nd(cls_target, train_indices)\n",
    "    cls_target = tf.cast(cls_target, dtype=tf.int32)\n",
    "    cls_target = tf.one_hot(cls_target, depth=conf.num_class)\n",
    "\n",
    "    # remove un-trained anchors from pred logit\n",
    "    logit0 = tf.gather_nd(predict_logits[..., 0], train_indices)\n",
    "    logit1 = tf.gather_nd(predict_logits[..., 1], train_indices)\n",
    "    predict_logits = tf.stack([logit0, logit1], axis=1)\n",
    "\n",
    "    # change negative tag from -1 to 0\n",
    "    cls_target = tf.where(cls_target > 0, cls_target, tf.zeros_like(cls_target))\n",
    "\n",
    "    # hard negative anchor mining\n",
    "    if conf.hard_negative_mining:\n",
    "        cls_target, predict_logits = hard_neg_mining(cls_target, predict_logits)\n",
    "\n",
    "    #  calculate the loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=cls_target, logits=predict_logits)\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def regr_loss(reg_target, predict_deltas, cls_target):\n",
    "    \"\"\"\n",
    "    :param reg_target: 2-d array,[batch_num,num_anchors,(dy,dx,dz,dh)]fg or bg\n",
    "    :param predict_deltas: 2-d array,[batch_num,num_anchors,(dy,dx,dz,dh)] fg or bg\n",
    "    :param cls_target: 2-d array,[batch_num,num_anchors]; 1,-1,0 for pos,neg and un-train anchors respectively\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # remove un-trained anchors\n",
    "    pos_indice = tf.where(tf.equal(cls_target, 1))\n",
    "    reg_target = tf.gather_nd(reg_target, pos_indice)\n",
    "    pred_deltas = tf.gather_nd(predict_deltas, pos_indice)\n",
    "    diff = tf.abs(reg_target - pred_deltas)\n",
    "    smooth_loss = tf.where(diff < 1, tf.pow(diff, 2) * 0.5, diff - 0.5)\n",
    "    loss = K.mean(smooth_loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def progressive_anchor_loss(e_reg_targets, e_cls_targets, o_reg_targets, o_cls_targets,\n",
    "                            fs_cls, fs_regr, ss_cls, ss_regr):\n",
    "    fs_cls_loss = cls_loss(o_cls_targets, fs_cls)\n",
    "    ss_cls_loss = cls_loss(e_cls_targets, ss_cls)\n",
    "    fs_regr_loss = regr_loss(o_reg_targets, fs_regr, o_cls_targets)\n",
    "    ss_regr_loss = regr_loss(e_reg_targets, ss_regr, e_cls_targets)\n",
    "\n",
    "    # fs_cls_loss = K.print_tensor(fs_cls_loss, message='fs_cls_loss = ')\n",
    "    # ss_cls_loss = K.print_tensor(ss_cls_loss, message='ss_cls_loss = ')\n",
    "    # fs_regr_loss = K.print_tensor(fs_regr_loss, message='fs_regr_loss = ')\n",
    "    # ss_regr_loss = K.print_tensor(ss_regr_loss, message='ss_regr_loss = ')\n",
    "\n",
    "    total_loss = fs_cls_loss + ss_cls_loss + fs_regr_loss + ss_regr_loss\n",
    "    # total_loss = K.print_tensor(total_loss, message='total_loss = ')\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    import numpy as np\n",
    "    cls_target = np.random.randint(-1, 2, [2, 8])\n",
    "    predict_logits = np.random.randint(-1, 10, [2, 8, 2])\n",
    "    cls_target = tf.constant(cls_target)\n",
    "    predict_logits = tf.constant(predict_logits, tf.float64)\n",
    "    see = cls_loss(cls_target, predict_logits)\n",
    "    to_run = [see]\n",
    "    sess = tf.Session()\n",
    "    for i in to_run:\n",
    "        print(i, '\\n', sess.run(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sub_5:0\", dtype=float64) Tensor(\"strided_slice_9:0\", shape=(?,), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Mul' Op has type float64 that does not match type float32 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    945\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"sub_5:0\", dtype=float64)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-20268f651376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mcls_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mpredict_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mto_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-20268f651376>\u001b[0m in \u001b[0;36mcls_loss\u001b[0;34m(cls_target, predict_logits)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# hard negative anchor mining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhard_negative_mining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mcls_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhard_neg_mining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m#  calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-20268f651376>\u001b[0m in \u001b[0;36mhard_neg_mining\u001b[0;34m(cls_target, predict_logits)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mloss_to_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_sum_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_to_rank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mloss_to_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_to_rank\u001b[0m  \u001b[0;31m# set loss for pos anchor to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_to_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpos_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1089\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4757\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4758\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4759\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4760\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4761\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    544\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 546\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type float64 that does not match type float32 of argument 'x'."
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 _*-\n",
    "\"\"\"\n",
    "@author: danna.li\n",
    "@date: 2019/4/25\n",
    "@file: loss_func.py\n",
    "@description:\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from dual_conf import current_config as conf\n",
    "\n",
    "\n",
    "def log_sum_exp(cls_target, predict_logits):\n",
    "    \"\"\"un-averaged confidence loss across all examples in a batch.\n",
    "    :param cls_target: 2-d tensor,[num_anchors,2 ]; 1,0 for pos,neg anchors respectively\n",
    "    :param predict_logits: 2-d tensor,[num_anchors,2] 2 for fg and bg\n",
    "    :return: loss,1-D tensor\n",
    "    \"\"\"\n",
    "    logit_max = tf.reduce_max(predict_logits)\n",
    "    loss = tf.log(tf.reduce_sum(tf.exp(predict_logits - logit_max), 1, keepdims=True)) + logit_max\n",
    "    cls_indice = tf.where(cls_target >= 1)\n",
    "    anchor_cls_logit = tf.gather_nd(predict_logits, cls_indice)\n",
    "    loss = tf.squeeze(loss)\n",
    "    loss = loss - anchor_cls_logit\n",
    "    return loss\n",
    "\n",
    "\n",
    "def hard_neg_mining(cls_target, predict_logits):\n",
    "    \"\"\"\n",
    "    select top 80 negtive anchors the contribute most loss to do the backward pass\n",
    "    :param cls_target:2-d tensor,[num_anchors,2 ]; 1,0 for pos,neg anchors respectively\n",
    "    :param predict_logits: 2-d tensor,[num_anchors,2] 2 for fg and bg\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loss_to_rank = log_sum_exp(cls_target, predict_logits)\n",
    "    print(loss_to_rank,cls_target[:, 0])\n",
    "    loss_to_rank = cls_target[:, 0] * loss_to_rank  # set loss for pos anchor to 0\n",
    "    _, neg_ind = tf.nn.top_k(loss_to_rank, 80)\n",
    "    pos_ind = tf.squeeze(tf.where(cls_target[:, 1] >= 1))\n",
    "    pos_ind = tf.cast(pos_ind, tf.int64)\n",
    "    neg_ind = tf.cast(neg_ind, tf.int64)\n",
    "    all_ind = tf.concat([pos_ind, neg_ind], axis=0)\n",
    "    cls_target = tf.gather(cls_target, all_ind)\n",
    "    predict_logits = tf.gather(predict_logits, all_ind)\n",
    "    return cls_target, predict_logits\n",
    "\n",
    "\n",
    "def cls_loss(cls_target, predict_logits):\n",
    "    \"\"\"\n",
    "    :param cls_target:2-d array,[batch_num,num_anchors]; 1,-1,0 for pos,neg and un-train anchors respectively\n",
    "    :param predict_logits: 3-d array,[batch_num,num_anchors,2] fg or bg\n",
    "    :return: classification loss of training anchors\n",
    "    \"\"\"\n",
    "    # remove un-trained anchors from cls_target and make cls_target to one-hot format\n",
    "    train_indices = tf.where(tf.not_equal(cls_target, 0))\n",
    "    cls_target = tf.gather_nd(cls_target, train_indices)\n",
    "    # change negative tag from -1 to 0\n",
    "    cls_target = tf.where(cls_target > 0, cls_target, tf.zeros_like(cls_target))\n",
    "    cls_target = tf.cast(cls_target,tf.int64)\n",
    "    cls_target = tf.one_hot(cls_target, depth=conf.num_class)\n",
    "\n",
    "    # remove un-trained anchors from pred logit\n",
    "    logit0 = tf.gather_nd(predict_logits[..., 0], train_indices)\n",
    "    logit1 = tf.gather_nd(predict_logits[..., 1], train_indices)\n",
    "    predict_logits = tf.stack([logit0, logit1], axis=1)\n",
    "    #predict_logits = tf.cast(predict_logits, dtype=tf.float32)\n",
    "\n",
    "    # hard negative anchor mining\n",
    "    if conf.hard_negative_mining:\n",
    "        cls_target, predict_logits = hard_neg_mining(cls_target, predict_logits)\n",
    "\n",
    "    #  calculate the loss\n",
    "    print(cls_target,predict_logits)\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=cls_target, logits=predict_logits)\n",
    "    loss = K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import numpy as np\n",
    "    cls_target = np.random.randint(-1, 2, [2, 8])\n",
    "    predict_logits = np.random.randint(-1, 10, [2, 8, 2])\n",
    "    cls_target = tf.constant(cls_target)\n",
    "    predict_logits = tf.constant(predict_logits, tf.float64)\n",
    "    loss = cls_loss(cls_target, predict_logits)\n",
    "    to_run = [loss]\n",
    "    sess = tf.Session()\n",
    "    for i in to_run:\n",
    "        print(i, '\\n', sess.run(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x):\n",
    "    \"\"\"Utility function for computing log_sum_exp while determining\n",
    "    This will be used to determine unaveraged confidence loss across\n",
    "    all examples in a batch.\n",
    "    Args:\n",
    "        x (Variable(tensor)): conf_preds from conf layers\n",
    "    \"\"\"\n",
    "    x_max = x.data.max()\n",
    "    return torch.log(torch.sum(torch.exp(x - x_max), 1, keepdim=True)) + x_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1,2],[1000,4],[3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_sum_exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_t = torch.Tensor([0,0,1]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_t.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.gather(1, conf_t.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sum_exp(x)-x.gather(1, conf_t.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/code/face/dual_shot')\n",
    "import numpy as np\n",
    "from net.dual_shot import test_net\n",
    "from prepare_data.generator import image_reader,augment\n",
    "from prepare_data.augment import Augmentation\n",
    "from prepare_data.widerface import WIDERFaceDetection\n",
    "from dual_conf import current_config as conf\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth= True\n",
    "sess = tf.Session(config=config)\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = WIDERFaceDetection(conf.data_path, 'train', None, None)\n",
    "image, gts, labels = image_reader(test_set)\n",
    "sub_img, gt_in_crop, sparse_label = augment(image, gts, labels, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.Variable(np.expand_dims(sub_img,0))\n",
    "ss_cls, _ = test_net(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "ss_cls = ss_cls.eval(session=sess)\n",
    "ss_cls = np.squeeze(ss_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(pred_logit,anchor_cls):\n",
    "    \"\"\" determine un-averaged confidence loss across all examples in a batch.\n",
    "    Args:\n",
    "        x (Variable(tensor)): conf_preds from conf layers\n",
    "    \"\"\"\n",
    "    logit_max = np.max(pred_logit)\n",
    "    loss = np.log(np.sum(np.exp(pred_logit - logit_max), 1)+ logit_max) \n",
    "    anchor_cls_logit = pred_logit[range(len(anchor_cls)),anchor_cls]\n",
    "    loss = loss - anchor_cls_logit\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = log_sum_exp(ss_cls,anchor_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ind = np.where(np.equal(anchor_cls, 1))[0]\n",
    "loss[pos_ind]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-loss).sort()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, loss_idx = loss.sort()\n",
    "_, idx_rank = loss_idx.sort(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cls = np.random.randint(0,2,(len(ss_cls),))\n",
    "anchor_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_cls_logit = ss_cls[range(len(anchor_cls)),anchor_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.exp(x - x_max), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_neg_mining(cls_target, predict_logits):\n",
    "    \"\"\"\n",
    "    select top 80 negtive anchors the contribute most loss to do the backward pass\n",
    "    :param cls_target:2-d tensor,[num_anchors,2 ]; 1,0 for pos,neg anchors respectively\n",
    "    :param predict_logits: 2-d tensor,[num_anchors,2] 2 for fg and bg\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loss_to_rank = log_sum_exp(cls_target, predict_logits)\n",
    "    loss_to_rank = cls_target[:, 0] * loss_to_rank  # set loss for pos anchor to 0\n",
    "    _, neg_ind = tf.nn.top_k(loss_to_rank, 80)\n",
    "    pos_ind = tf.squeeze(tf.where(cls_target[:, 1] >= 1))\n",
    "    pos_ind = tf.cast(pos_ind, tf.int64)\n",
    "    neg_ind = tf.cast(neg_ind, tf.int64)\n",
    "    all_ind = tf.concat([pos_ind, neg_ind], axis=0)\n",
    "    cls_target = tf.gather(cls_target, all_ind)\n",
    "    predict_logits = tf.gather(predict_logits, all_ind)\n",
    "    return cls_target, predict_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
